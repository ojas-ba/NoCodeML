# NoCodeML Platform ğŸš€

> **Hackathon Project** - A full-stack No-Code Machine Learning platform that democratizes AI/ML by enabling anyone to build, train, and deploy models through an intuitive web interface.

![Python](https://img.shields.io/badge/Python-3.11+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green)
![React](https://img.shields.io/badge/React-18-blue)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue)

---

## ğŸ“¸ Preview

![NoCodeML Platform Landing Page](./screenshots/landing-page.png)
*NoCodeML Platform - Your gateway to no-code machine learning*

---

## ğŸ¯ What We Built

NoCodeML is an end-to-end machine learning platform that removes the coding barrier from ML development. Users can:
- Upload datasets (CSV, Excel, Parquet)
- Perform automated exploratory data analysis with interactive visualizations
- Select and configure ML models from 8 powerful algorithms
- Train models asynchronously with real-time progress tracking
- Make predictions on new data
- Compare model performance across different algorithms

**Tech Stack:** FastAPI + React + PostgreSQL + Redis + Celery + Docker  
**Models:** 4 Classification + 4 Regression (Logistic/Linear, Random Forest, XGBoost, LightGBM)

### Why This Matters
Machine learning shouldn't require a CS degree. NoCodeML makes ML accessible to:
- Business analysts exploring data patterns
- Students learning ML concepts
- Researchers testing hypotheses quickly
- Anyone with data and questions to answer

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Node.js 18+ (with npm or bun)

### Setup (5 minutes)

```bash
# 1. Clone and navigate
git clone <repo-url>
cd V2_NoCodeML

# 2. Backend - Start all services (API, PostgreSQL, Redis, Celery Worker)
cd Backend
cp .env.example .env
docker-compose up -d
docker-compose exec fastapi_app alembic upgrade head

# 3. Frontend - Install and run
cd ../Frontend
npm install  # or: bun install
cp .env.example .env
npm run dev  # or: bun run dev
```

### Access Points
- **Application:** http://localhost:5173
- **API Docs:** http://localhost:8000/docs
- **Backend:** http://localhost:8000

---

## âœ¨ Core Features

### 1ï¸âƒ£ Dataset Management
- **Multi-format Support:** Upload CSV, Excel (.xlsx/.xls), and Parquet files
- **Smart Metadata Extraction:** Automatic detection of data types, row/column counts
- **Quick Preview:** View dataset samples directly in the browser
- **Full CRUD Operations:** Rename, update, delete, and manage multiple datasets

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)
- **Automated Statistics:** Mean, median, std deviation, quartiles for all numeric columns
- **Missing Value Analysis:** Identify and visualize data quality issues
- **Correlation Matrix:** Interactive heatmap showing feature relationships
- **Smart Visualizations:**
  - Distribution plots (histograms)
  - Box plots for outlier detection
  - Scatter plots for bivariate analysis
  - Powered by Plotly (backend) and Recharts (frontend)
- **Outlier Detection:** IQR-based statistical outlier identification

### 3ï¸âƒ£ Experiment Workflow
- **Project Organization:** Create experiments linked to specific datasets
- **Version Control:** Duplicate experiments to test different configurations
- **Configuration Persistence:** Save and load model configurations
- **5-Step Guided Workflow:** Analysis â†’ Config â†’ Training â†’ Results â†’ Prediction

### 4ï¸âƒ£ Machine Learning Models (8 Algorithms)

**Classification** (4 models)
- **Logistic Regression** - Fast linear classifier for binary/multi-class problems
- **Random Forest** - Ensemble of decision trees with feature importance
- **XGBoost** - Gradient boosting with regularization and high accuracy
- **LightGBM** - Ultra-fast gradient boosting optimized for speed

**Regression** (4 models)
- **Linear Regression** - Simple and interpretable linear model
- **Random Forest** - Robust ensemble regressor with feature importance
- **XGBoost** - High-accuracy gradient boosting for regression
- **LightGBM** - Memory-efficient and fast gradient boosting

### 5ï¸âƒ£ Model Training System
- **Asynchronous Processing:** Celery-based distributed task queue
- **Real-time Status:** Live progress tracking with job status updates
- **Multi-model Training:** Train multiple algorithms simultaneously
- **Smart Hyperparameters:** Pre-configured optimal defaults for each model
- **Comprehensive Metrics:**
  - **Classification:** Accuracy, Precision, Recall, F1-Score, ROC-AUC
  - **Regression:** RÂ², MAE, MSE, RMSE
- **Model Persistence:** Automatic saving of trained models with joblib
- **Feature Importance:** Supported for Random Forest, XGBoost, and LightGBM models

### 6ï¸âƒ£ Prediction Engine
- **Single Predictions:** Real-time predictions on individual data points
- **Batch Processing:** Upload CSV files for bulk predictions
- **Result Export:** Download predictions as CSV files
- **Confidence Scores:** Probability estimates for classification tasks

### 7ï¸âƒ£ User Experience
- **Authentication:** JWT-based secure user system
- **Modern UI:** Built with shadcn/ui components and Tailwind CSS
- **Responsive Design:** Works seamlessly on desktop and mobile
- **Interactive Charts:** Dynamic, zoomable visualizations
- **Real-time Feedback:** Toast notifications and progress indicators

---

## ğŸ—ï¸ Technical Architecture

### Backend Stack
| Component | Technology | Purpose |
|-----------|-----------|---------|
| API Framework | FastAPI (Python 3.11) | High-performance async REST API |
| Database | PostgreSQL 15 | Persistent storage for users, datasets, experiments |
| ORM | SQLAlchemy (async) | Database abstraction layer |
| Migrations | Alembic | Database schema version control |
| Task Queue | Celery + Redis | Asynchronous ML model training |
| ML Libraries | scikit-learn, XGBoost, LightGBM | 8 optimized ML algorithms |
| Data Processing | pandas, numpy, openpyxl, pyarrow | Dataset handling and transformations |
| Visualization | Plotly | Server-side chart generation |
| Authentication | JWT (python-jose) | Secure user authentication |
| Containerization | Docker + Docker Compose | Easy deployment and scaling |

### Frontend Stack
| Component | Technology | Purpose |
|-----------|-----------|---------|
| Framework | React 18 + TypeScript | Type-safe component-based UI |
| Build Tool | Vite | Fast development and optimized builds |
| UI Library | shadcn/ui (Radix UI) | Accessible, customizable components |
| Styling | Tailwind CSS | Utility-first responsive design |
| State Management | React Context API | Global state for auth, experiments |
| Data Fetching | TanStack Query | Caching and server state management |
| Routing | React Router v6 | Client-side navigation |
| Charts | Recharts | Interactive data visualizations |

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Client Browser                         â”‚
â”‚                    (React + TypeScript)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/REST
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FastAPI Backend                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Auth API   â”‚  â”‚ Dataset API  â”‚  â”‚ Training API â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                  â”‚
         â–¼                 â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚ â”‚    Redis     â”‚ â”‚  Celery Worker  â”‚
â”‚   (Database)    â”‚ â”‚ (Task Queue) â”‚ â”‚ (ML Training)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```
V2_NoCodeML/
â”œâ”€â”€ Backend/                  # FastAPI backend application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/             # API route handlers
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py      # Authentication endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ datasets.py  # Dataset management
â”‚   â”‚   â”‚   â”œâ”€â”€ eda.py       # Exploratory data analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ experiments.py  # Experiment CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py    # ML model catalog
â”‚   â”‚   â”‚   â”œâ”€â”€ training.py  # Model training
â”‚   â”‚   â”‚   â””â”€â”€ predictions.py  # Prediction endpoints
â”‚   â”‚   â”œâ”€â”€ core/            # Core configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py    # App settings
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py  # Auth utilities
â”‚   â”‚   â”‚   â””â”€â”€ model_cache.py  # Model caching
â”‚   â”‚   â”œâ”€â”€ db/              # Database configuration
â”‚   â”‚   â”œâ”€â”€ models/          # SQLAlchemy ORM models
â”‚   â”‚   â”œâ”€â”€ schemas/         # Pydantic validation schemas
â”‚   â”‚   â”œâ”€â”€ services/        # Business logic layer
â”‚   â”‚   â”œâ”€â”€ worker/          # Celery tasks
â”‚   â”‚   â””â”€â”€ main.py          # Application entry point
â”‚   â”œâ”€â”€ alembic/             # Database migrations
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yaml
â”‚
â””â”€â”€ Frontend/                # React frontend application
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/      # Reusable UI components
    â”‚   â”‚   â”œâ”€â”€ datasets/    # Dataset components
    â”‚   â”‚   â”œâ”€â”€ experiments/ # Experiment components
    â”‚   â”‚   â”œâ”€â”€ playground/  # ML workflow components
    â”‚   â”‚   â””â”€â”€ ui/          # shadcn/ui components
    â”‚   â”œâ”€â”€ contexts/        # React Context providers
    â”‚   â”œâ”€â”€ hooks/           # Custom React hooks
    â”‚   â”œâ”€â”€ pages/           # Page components
    â”‚   â”œâ”€â”€ services/        # API services
    â”‚   â””â”€â”€ types/           # TypeScript type definitions
    â”œâ”€â”€ package.json
    â””â”€â”€ vite.config.ts
```

---

## ğŸ› ï¸ Development Guide

### Backend Commands

```bash
# Start all services (API, PostgreSQL, Redis, Celery)
cd Backend
docker-compose up -d

# View logs
docker-compose logs -f fastapi_app
docker-compose logs -f celery_worker

# Database migrations with Alembic
docker-compose exec fastapi_app alembic upgrade head              # Apply all migrations
docker-compose exec fastapi_app alembic revision --autogenerate -m "add_column"  # Create new migration
docker-compose exec fastapi_app alembic downgrade -1              # Rollback last migration
docker-compose exec fastapi_app alembic current                   # Show current revision
docker-compose exec fastapi_app alembic history                   # Show migration history

# Access container shell
docker-compose exec fastapi_app bash

# Stop all services
docker-compose down
```

### Frontend Commands

```bash
cd Frontend

# Development server (hot reload)
npm run dev          # or: bun run dev

# Production build
npm run build        # or: bun run build

# Preview production build
npm run preview

# Lint code
npm run lint
```

### Environment Configuration

**Backend** (`Backend/.env`):
```env
POSTGRES_USER=myuser
POSTGRES_PASSWORD=mysecretpassword
POSTGRES_DB=nocodeml_db
DATABASE_URL=postgresql+psycopg://myuser:mysecretpassword@postgres:5432/nocodeml_db
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0
SECRET_KEY=your-secret-key-change-in-production
```

**Frontend** (`Frontend/.env`):
```env
VITE_API_URL=http://localhost:8000
```

---

## ğŸ“¡ API Reference

Full interactive API documentation: **http://localhost:8000/docs**

### Core Endpoints

| Category | Endpoint | Method | Description |
|----------|----------|--------|-------------|
| **Auth** | `/api/v1/auth/register` | POST | Register new user |
| | `/api/v1/auth/login` | POST | Login and get JWT token |
| **Datasets** | `/api/v1/datasets` | GET, POST | List/upload datasets |
| | `/api/v1/datasets/{id}` | GET, PUT, DELETE | Manage dataset |
| | `/api/v1/datasets/{id}/preview` | GET | Preview dataset rows |
| **Experiments** | `/api/v1/experiments` | GET, POST | List/create experiments |
| | `/api/v1/experiments/{id}` | GET, PUT, DELETE | Manage experiment |
| | `/api/v1/experiments/{id}/duplicate` | POST | Duplicate experiment |
| **EDA** | `/api/v1/eda/{dataset_id}/summary` | GET | Get statistics & correlations |
| | `/api/v1/eda/plot` | POST | Generate visualization |
| **Models** | `/api/v1/models` | GET | List all 8 ML models |
| | `/api/v1/models/{task_type}` | GET | Filter by classification/regression |
| **Training** | `/api/v1/training/start` | POST | Start async training jobs |
| | `/api/v1/training/runs/{job_id}` | GET | Get training status & results |
| **Predictions** | `/api/v1/predictions/batch` | POST | Batch predictions from CSV |
| | `/api/v1/predictions/{batch_id}` | GET | Get prediction results |

---

## ğŸ—„ï¸ Database Schema & Migrations

### Alembic Migrations

The project uses **Alembic** for database schema version control, ensuring smooth schema evolution across environments.

#### Current Migrations

1. **`001_create_datasets_table.py`** - User datasets table
   - Stores uploaded dataset metadata (name, file path, rows, columns)
   - User-scoped with foreign key to users table

2. **`002_create_experiments_table.py`** - ML experiments table
   - Links experiments to datasets
   - Stores experiment configuration (features, target, task type)

3. **`003_create_training_tables.py`** - Training infrastructure
   - Training jobs table (status, model type, hyperparameters)
   - Training results table (metrics, feature importance)

4. **`004_create_training_runs_table.py`** - Enhanced training tracking
   - Detailed job execution tracking
   - Training logs and progress monitoring

5. **`005_create_prediction_batches_table.py`** - Prediction system
   - Batch prediction management
   - Prediction results storage

#### Migration Commands

```bash
# Initialize database (first time setup)
docker-compose exec fastapi_app alembic upgrade head

# Create new migration after model changes
docker-compose exec fastapi_app alembic revision --autogenerate -m "add_new_column"

# Apply migrations
docker-compose exec fastapi_app alembic upgrade head

# Rollback last migration
docker-compose exec fastapi_app alembic downgrade -1

# View current database version
docker-compose exec fastapi_app alembic current

# View migration history
docker-compose exec fastapi_app alembic history --verbose
```

### Database Tables

| Table | Purpose | Key Columns |
|-------|---------|-------------|
| `users` | User authentication | email, hashed_password, created_at |
| `datasets` | Uploaded datasets | name, file_path, num_rows, num_columns, user_id |
| `experiments` | ML experiments | name, dataset_id, config (JSONB), user_id |
| `training_jobs` | Training tasks | status, model_type, experiment_id |
| `training_results` | Model metrics | accuracy, precision, f1_score, job_id |
| `training_runs` | Run tracking | start_time, end_time, error_message |
| `training_logs` | Progress logs | message, metrics_json, timestamp |
| `prediction_batches` | Predictions | input_file_path, output_file_path, status |

---

## ğŸ“ Technical Highlights

### What We Built
- **Full ML Pipeline:** Complete workflow from data upload to predictions
- **8 Production-Ready Models:** 4 classification + 4 regression algorithms (Logistic/Linear Regression, Random Forest, XGBoost, LightGBM)
- **Async Training:** Celery + Redis for non-blocking model training
- **Type-Safe Frontend:** Full TypeScript coverage with proper interfaces
- **Interactive Viz:** Server-side Plotly, client-side Recharts for data exploration
- **Microservices Architecture:** Separate containers for API, worker, database, cache

### Challenges Overcome
1. **Long-running Tasks:** Implemented Celery task queue to handle training jobs that can take minutes
2. **State Synchronization:** Real-time status updates between training worker and UI via polling
3. **Type Safety:** Consistent TypeScript types across 50+ React components
4. **Data Validation:** Robust Pydantic schemas preventing bad data from reaching ML pipeline
5. **Model Persistence:** Efficient joblib serialization and retrieval of trained models

### Key Architecture Decisions
| Decision | Rationale |
|----------|-----------|
| FastAPI over Flask | Native async support, automatic OpenAPI docs, better performance |
| Celery for training | Prevents API timeouts on long-running ML tasks |
| React Context API | Simpler than Redux for our scope; sufficient for auth/experiment state |
| Docker Compose | Single-command dev environment with all services |
| PostgreSQL | ACID compliance for experiment/training data |
| shadcn/ui | Accessible components, full customization control |

---

## ğŸš€ Future Enhancements

**Short-term:**
- [ ] Hyperparameter tuning (GridSearchCV, RandomSearchCV)
- [ ] Advanced feature engineering (StandardScaler, OneHotEncoder, PCA)
- [ ] Model comparison dashboard with side-by-side metrics
- [ ] Export trained models (download as .pkl/.onnx)

**Long-term:**
- [ ] AutoML integration (auto-sklearn, TPOT)
- [ ] Time series forecasting models (ARIMA, Prophet)
- [ ] Deep learning support (TensorFlow, PyTorch)
- [ ] Team collaboration & shared experiments
- [ ] Model versioning and A/B testing
- [ ] Scheduled predictions & model serving
- [ ] Cloud deployment (AWS/GCP/Azure)

---

## ğŸ‘¥ Team & Credits

**Project Type:** Hackathon Submission  
**Built by:** [Your Team Name]  
**Timeframe:** [Hackathon Duration]

### Technology Credits
- **FastAPI** - Modern async Python web framework
- **React 18** - UI library with hooks
- **shadcn/ui** - Accessible component library
- **scikit-learn** - Linear models and Random Forest
- **XGBoost & LightGBM** - High-performance gradient boosting
- **Plotly & Recharts** - Data visualization
- **Celery** - Distributed task queue
- **PostgreSQL** - Reliable database
- **Docker** - Containerization

---

## ğŸ“ Get in Touch

- **Demo Video:** [Add your demo video link]
- **Live Demo:** [Add deployed link if available]
- **API Docs:** http://localhost:8000/docs (when running locally)
- **Issues/Feedback:** [GitHub Issues](your-repo-url/issues)

---

**Made with â¤ï¸ and lots of â˜• during [Hackathon Name]**  
*Democratizing Machine Learning, One Click at a Time* ğŸš€
